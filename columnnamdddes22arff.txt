Furthermore, the angle between a single feature and the PC-axis can be interpreted as the correlation between these two, a small angle indicating strong positive correlation. This is very visual and makes the analysis part interesting: we can see from the plot that nearly all of the variables in connection with PC1 have relatively small angles and thus strong positive connection with PC1. Those ariables contributing to PC2 also have a small angle with the PC2-axis, so the correlation between the PC2 and them is also significantly positive. The arrows which are in a close to 90 degrees angle with either PC1 or PC2 have close to a 0 correlation with these PCs, so indeed for example labRatioFM doesn’t correlate with PC1 - which is an element of PCA - the axii are uncorrelated. 



Next, to reduce the dimensionality of this data set, I'll move on to perform Primary Component Analysis (PCA) on it. A Principal Component Analysis (abbreviated as PCA) can be conducted on the dataset to lower its dimensionality using the singular value decomposition (SVD) method. The SVD literally decomposes a matrix and produces a product of smaller matrices, which brings out the most important components, and in statistics, PCA aims to do exactly that. It represents the data at hand in two dimensions with respect to Principal components - the components which explain different proportions of variance of the original variables, or in other words, features. The first Principal component always explains the largest proportion of variance along the features, and the importance of the PC is relative to the order in which it is represented in the PCA: for example, PC2 explains the second largest proportion of variance and PC3 the third largest and so on. Usually only two principal components explain the most significant amount of variance, hece the two-dimensionality of the PCA and the resulting biplot (bi = two) with arrows representing the correlation between the variables with each other and with the two PCs. Consequently, the Principal components are also uncorrelated, which means that the angle between them is 90 degrees (which corresponds to a 0 correlation).

To do that we need to convert the data set into a data frame and scale it - otherwise the skewed distributions of the variables and the differing variances would lead PCA to "perceive" the variables with larger variance as also more important, because PCA is impacted by the scaling of the features.



With the initial settings the plot wasn't exactly readable; because of the quite remarkable outliers (New York, for example) that made the scale of the x- and y-axii very wide. That's why I used xlim and ylim to limit the range of the axii and produce a more readable biplot. Now, from the above plot we can see from the direction of the arrows, which features contribute to either of the primary components. Clearly, percent of people in dense housing, percent of male persons never married, percent of homeless as well as violent crimes per population (our target variable for linear regression) percent of people with lower than or 9th grade education and percent of African Amrican of the population correlate with the first principal component. Also percent of working moms with under 18 year old kids seems to fall in this category, however, the arrow points to the opposite direction. Features that contribute to both of the first primary components but might contribute more to the PC2, are percent of people under poverty rate, median and per capita income and percent of employed people, which all have to do with income related aspects. These include also percent of people using public transport, percent of recently immigrated of population, number of homeless, population and population density - population related features which also have to do with income. Furthermore, the angle between a single feature and the PC-axis can be interpreted as the correlation between these two, a small angle indicating strong positive correlation. This is very visual and makes the analysis part interesting: we can see from the plot that nearly all of the variables in connection with PC1 have relatively small angles and thus strong positive connection with PC1. Those ariables contributing to PC2 also have a small angle with the PC2-axis, so the correlation between the PC2 and them is also significantly positive. The arrows which are in a close to 90 degrees angle with either PC1 or PC2 have close to a 0 correlation with these PCs, so indeed for example labRatioFM doesn’t correlate with PC1 - which is an element of PCA - the axii are uncorrelated. 
